\documentclass[11pt]{report}

\usepackage[pdftex]{geometry}
\geometry{a4paper,left=2.8cm,right=2.8cm,top=1.5cm,bottom=1.5cm,twoside}

\usepackage{amssymb}
\usepackage{enumerate}
\usepackage{graphicx}
	\graphicspath{./Comments/}
\usepackage[many]{tcolorbox}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{subfigure}
\usepackage{bm,bbm}
\usepackage{float}
\usepackage{siunitx}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\newtcolorbox{reviewbox}[1]{
colback = white!5!white,
colframe = purple!75!black,
fonttitle=\bfseries,
title=#1
}

\newtcolorbox{responsebox}[1]{
	colback = white!5!white,
	colframe = white!75!black,
	fonttitle=\bfseries,
	title=#1
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}


\begin{center}
\large{\textbf{Response Letter to Reviewer \# 1}}

\vglue 0.3cm

\huge{ Quantifying Roughness in SAR Imagery with the Rényi Entropy\\ (GRSL-00722-2025)}
\end{center}

%\authors
\begin{center}
\textbf{Janeth Alpala,   Abraao D.\ C.\ Nascimento, Alejandro C.\ Frery  }
\end{center}

\date{\today}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{0.5cm}
\noindent Dear Editors
\bigskip

\noindent We are grateful to the reviewers for the valuable comments and the time spent on checking our manuscript. 
We have addressed their comments towards improving the paper contents and presentation. 
Below we detail the changes and updates incorporated into the manuscript in this round of review.

\medskip


%-------------------------------------
\begin{reviewbox}{Comment 1}
1. The manuscript uses Rényi Entropy to estimate the surface roughness using SAR intensity data. However, the novelty aspect is not clear to this reviewer. Is this the sampling technique for the non-parametric estimation? The non-parametric estimation is already existing in the literature.

\end{reviewbox}

\begin{responsebox}{Response}


We thank the reviewer for raising this important point. While non-parametric entropy estimation is indeed present in the literature, we have not found prior works that apply a non-parametric estimator of the Rényi entropy specifically for heterogeneity detection in SAR imagery.

Our contribution lies in formulating a hypothesis test that uses the entropy estimator as a test statistic to distinguish between homogeneous and heterogeneous regions. Classical parametric inference alternatives, such as likelihood ratio or Wald tests, are not applicable here due to the limiting behavior of the roughness parameter (\(\alpha \to -\infty\)) under the null hypothesis.

In addition, we enhance the non-parametric Rényi entropy estimator by incorporating a bootstrap based bias correction technique. This resampling strategy not only reduces the estimator’s bias but also improves the accuracy of entropy estimation, particularly when working with small sample sizes. This improvement is especially relevant in practical SAR image analysis, where estimations are commonly performed over small windows, such as \(7 \times 7\) pixels.

Moreover, our aim is to propose a statistically grounded, interpretable approach that provides analytical significance measures. This distinguishes our method from data-driven alternatives, and makes it especially useful for unsupervised analysis or scenarios with limited ground-truth information.



\begin{quote}
	\textcolor{blue}{ We have clarified these contributions in the revised manuscript, in the final paragraph of the Introduction.}
\end{quote}

\end{responsebox}

\vspace{1em}
\begin{reviewbox}{Comment 2}
2. The methodology is mostly indicates the heterogeneity in a SAR image. The terminology ``Roughness'' generally refers to the surface roughness irrespective of the landcover classes. However, the proposed technique includes everything which are existing within a resolution. Therefore, in the title of the manuscript, the ``Roughness'' can be changed to ``Heterogeneity''.
\end{reviewbox}

\begin{responsebox}{Response}

We appreciate the reviewer’s observation. In our work, the term \emph{roughness} is used in a statistical sense, following the interpretation of the parameter $\alpha$ in the $\mathcal{G}^0_I$ distribution. This parameter reflects the degree of texture or variability within the resolution cell, which may result from both surface irregularities and land cover heterogeneity.
 While we believe the term is appropriate in this context, we are open to revising the manuscript title from ``Roughness'' to ``Heterogeneity'' to improve clarity and better align with remote sensing terminology.

Accordingly, we have revised the manuscript title to:
\begin{quote}
	\textcolor{blue}{
	``Quantifying Heterogeneity in SAR Imagery with the Rényi Entropy.''}
\end{quote}
\end{responsebox}

\vspace{1em}
\begin{reviewbox}{Comment 3}
3. Why the p-values are very high over the areas which have the dominant surface scattering? Should it not be low if the proposed technique is estimating the entropy precisely? It looks like the proposed method better estimates over the heterogeneous areas as compared to homogeneous areas.
\end{reviewbox}

\begin{responsebox}{Response}

We thank the reviewer for this observation. However, we believe there may be a misunderstanding regarding the interpretation of $p$-values. 
In our formulation, the null hypothesis $H_0$ assumes that a region is homogeneous. Therefore, high $p$-values ($p > 0.05$) indicate that the data are consistent with homogeneity, while low $p$-values ($p < 0.05$) suggest statistical evidence of heterogeneity.


This is the intended behavior of the test, and the observed $p$-value patterns in the detection maps confirm its correct functioning.

Regarding the reviewer’s observation that the method appears to “better estimate” over heterogeneous areas: this is a reflection of the test’s design. In heterogeneous areas, the difference between the estimated and theoretical entropy is larger, producing low $p$-values that correctly signal a rejection of the homogeneity hypothesis. 
In homogeneous areas, the difference is smaller, and the high $p$-values reflect that the null hypothesis is not rejected. Therefore, the method is working consistently across both types of regions.


\begin{quote}
\textcolor{blue}{
We have clarified this point in the revised manuscript by adding a paragraph at the end of Section~III-D,  which explains how the $p$-value maps are constructed from sliding windows and how they should be interpreted.
}
\end{quote}
\end{responsebox}


\vspace{5em}
\begin{reviewbox}{Comment 4}
4. How is the dependence of the proposed technique on the additive and multiplicative noises which remains in the SAR data?
\end{reviewbox}
\begin{responsebox}{Response}


The proposed technique explicitly models the multiplicative noise (speckle) inherent in SAR intensity data. 
It assumes fully developed speckle in homogeneous areas, which is commonly modeled by a Gamma distribution. 

Additive noise is not considered in the model because it is usually very small in SAR images that have been properly calibrated.
 In our experiments, we use SAR images in intensity format (e.g., HH) that are radiometrically and geometrically corrected. 
Because the method analyzes small windows and uses non-parametric entropy estimation, it is relatively robust to small residual noise that may remain after standard preprocessing, such as calibration and terrain correction. 
We do not apply any additional filtering in order to keep the texture information that is important for detecting heterogeneity.


\end{responsebox}

\vspace{2em}
\begin{reviewbox}{Comment 5}
5. Fig 6, 7 and 8 show the detection of heterogeneous areas. However, a statistical measure indicating the detection performance is absent.
\end{reviewbox}

\begin{responsebox}{Response}
In the revised manuscript, we have included a quantitative performance evaluation to complement the visual comparison.

Specifically, we manually defined eight polygonal regions of interest (ROIs) in each SAR image: four clearly homogeneous areas ( water, flat croplands) and four clearly heterogeneous areas (urban centers). Each ROI was labeled as either homogeneous (class 0, shown in blue) or heterogeneous (class 1, in red),  as illustrated in Figs.~5a, 6a, and 7a (corresponding to Figs.~6a, 7a, and 8a in the original submission).

These ROIs were then rasterized to create a partial ground-truth mask. 
We thresholded the $p$-value maps at $0.05$ significance level to generate binary decision maps: values below this threshold were labeled as heterogeneous (1), and values above or equal to the threshold as homogeneous (0). 
The resulting prediction maps were compared against the ground-truth labels within the ROIs. 
From this comparison, we computed statistical performance metrics such as F1-score, kappa coefficient, and overall accuracy, summarized in Table~III.

Additionally, to assess performance across all decision thresholds, we computed ROC curves and the area under the curve (AUC) for each method in Fig. 9.

\begin{quote}
\textcolor{blue}{These additions appear in Section~IV-C of the revised manuscript.
}
\end{quote}
\end{responsebox}


\vspace{9em}


\begin{reviewbox}{Comment 6}
6. The color bars and the font size of the texts needs to be improved so that it can be clearly visible.
\end{reviewbox}

\begin{responsebox}{Response}
We thank the reviewer for this suggestion. In response, we improved Figures~6–8 (now Figs.~5–7) by increasing the font size of all labels and standardizing the size and placement of the color bars to enhance clarity and readability.

Furthermore, we unified the colormap used in the $p$-value maps across all three scenes to ensure visual consistency and facilitate direct comparison between results. 

Additionally, we added the corresponding optical images alongside each SAR image to better support the visual interpretation of heterogeneous regions.

\end{responsebox}

\vspace{0.5em} 
\begin{reviewbox}{Comment 7}
7. Why the authors are focusing on the low MSE, not the low bias while selecting the value of lambda?
\end{reviewbox}

\begin{responsebox}{Response}

While both bias and MSE are important criteria, we prioritized the MSE because it incorporates both the bias and the variance of the estimator. 
Specifically, the MSE is defined as the sum of the squared bias and the variance, providing a more comprehensive measure of estimator accuracy.

In our simulations, we found that for $L > 1$, the choice $\lambda = 0.9$ consistently yielded the lowest MSE while maintaining a low bias, thus offering a favorable trade-off between bias and variance. Although some values of $\lambda$ (e.g., $0.85$) showed slightly lower bias, they resulted in higher overall MSE due to increased variance.

We illustrate the case for $L = 5$ in Fig. 2, but similar trends were observed for other values of $L > 1$, confirming the robustness of $\lambda = 0.9$ and motivating its selection in the Rényi entropy estimator.
\begin{quote}
\textcolor{blue}{We have clarified this point in Section~III-A, where we explicitly justify the choice of $\lambda = 0.9$ based on the trade-off between bias and MSE.}
\end{quote}
\end{responsebox}

\vspace{0.5em}

\begin{reviewbox}{Comment 8}
8. "We aim to determine the optimal order $\lambda$ for the Rényi entropy estimator for a sample size $n=49$." From where these 49 samples are taken?
\end{reviewbox}

\begin{responsebox}{Response}


The 49 samples refer to synthetic data generated from the Gamma distribution, which models fully developed speckle in homogeneous regions.

To determine the optimal value of $\lambda$, we conducted a Monte Carlo simulation with $R = 1000$ replications.
 In each replication, a sample of size $n = 49$ was drawn from the $\Gamma_{\text{SAR}}(L = 5, \mu = 1)$ distribution. Bias and MSE were computed across several $\lambda$ values to select the most robust option.

The choice of $n = 49$ corresponds to a $7 \times 7$ window, which is commonly used in SAR image processing as it strikes a balance between capturing local detail and providing enough data for reliable statistical analysis.
\begin{quote}
\textcolor{blue}{We have clarified the origin of the samples $n = 49$ in Section~III-A.}
\end{quote}
\end{responsebox}


\end{document}

